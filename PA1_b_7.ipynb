{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\n_______________________________________Answer to Question 7___________________________________________\\n\")\n",
    "\n",
    "#loading the training dataset\n",
    "training_set = pd.read_csv(\"DS2-train.csv\") \n",
    "df = pd.DataFrame(training_set)\n",
    "\n",
    "#Dataframe was taking first row as the header. Hence replicating 1st row. \n",
    "df.columns = df.iloc[0]\n",
    "df = df[0:]\n",
    "\n",
    "\n",
    "Xtrain = df.iloc[:, 0:96]\n",
    "Ytrain = df.iloc[:, 96]\n",
    "\n",
    "#Loading the test dataset\n",
    "test_set = pd.read_csv(\"DS2-test.csv\") \n",
    "df2 = pd.DataFrame(test_set)\n",
    "\n",
    "#Dataframe was taking first row as the header. Hence replicating 1st row. \n",
    "df2.columns = df2.iloc[0]\n",
    "df2 = df2[0:]\n",
    "\n",
    "Xtest = df2.iloc[:, 0:96]\n",
    "Ytest = df2.iloc[:, 96]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the test are :::::::::::::::: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       1.00      0.79      0.88        19\n",
      "         1.0       0.83      1.00      0.91        20\n",
      "\n",
      "    accuracy                           0.90        39\n",
      "   macro avg       0.92      0.89      0.90        39\n",
      "weighted avg       0.91      0.90      0.90        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs', max_iter=150)\n",
    "\n",
    "print(\"\\n_______________________________________Logistic Regression___________________________________________\\n\")\n",
    "\n",
    "#Normalizing the data for better convergence\n",
    "from sklearn import preprocessing\n",
    "normalizer = preprocessing.MinMaxScaler()\n",
    "x_train = normalizer.fit_transform(Xtrain)\n",
    "\n",
    "#Fitting the data\n",
    "clf.fit(x_train, Ytrain);\n",
    "y_pred = clf.predict(Xtest)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#printing results on test \n",
    "print(\"Results on the test are :::::::::::::::: \\n\")\n",
    "print(classification_report(Ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________________Logistic Regression with L1 regularization ___________________________________________\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature:\n",
      " [[-0.18000647 -7.33299033  4.19061386  0.         -0.29667936 -3.62299076\n",
      "   0.          0.          5.6928178  -2.02955712  1.70367536 -0.94880614\n",
      "   2.91147975  0.         -0.78782217  1.71246776 -2.41083295  2.41696214\n",
      "   0.31780292  0.          0.79885137 -2.26520313  0.         -3.53815421\n",
      "   0.          0.         -2.23309687  0.         -3.49528814  0.\n",
      "  -2.98258435  6.28237906 -4.87065208  0.          0.         -7.25553814\n",
      "   0.         -0.38275227  0.          0.         -3.11626754  0.\n",
      "   0.         -8.99161186 -7.67187989  7.32858719 -1.49352597  0.\n",
      "  -2.81812951  0.          5.00620316 -2.53553369  4.6531166   0.\n",
      "   1.25608364  0.          2.4871702   0.          0.81870135  0.\n",
      "   0.          8.06608648 -2.84848221  4.1584126   9.55373198  5.79833238\n",
      "   0.          8.19630122  4.55009271  0.          1.33543564  1.81687589\n",
      "   0.          3.07248758  0.         -0.62074364  4.36868992  0.\n",
      "  -0.64418599  0.          4.97889213  0.         -5.93609386  0.\n",
      "   0.         -0.87358762  0.         -5.7566456   0.         -6.20544495\n",
      "   0.         -4.60683182 -5.44209753  0.         -0.2917485  -4.38644806]]\n",
      "\n",
      "Results on the test are :::::::::::::::: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.94      0.89      0.92        19\n",
      "         1.0       0.90      0.95      0.93        20\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.92      0.92      0.92        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature:\n",
      " [[-2.38361226 -1.15490173  0.          0.         -0.61262596 -0.12199412\n",
      "   0.          0.          0.          0.          0.43947008  0.\n",
      "   0.          0.          0.          0.15585659  0.          1.27247918\n",
      "   0.          0.          0.          0.         -0.8450477   0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.54489102 -0.71818684  0.          0.          0.\n",
      "   0.         -0.46258149  0.          0.         -1.48456351  0.\n",
      "   0.         -2.16877105  0.          0.          0.35983622  0.\n",
      "   0.          0.          1.54893105  0.          1.55281193  0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          4.57839979  1.99617719\n",
      "   0.01615889  0.          2.82992704  0.          0.96929381  0.\n",
      "   0.          0.47972232  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.         -2.6608707  -0.7203789\n",
      "  -0.41832723 -1.43809088  0.         -5.93770689  0.         -0.6738103\n",
      "  -0.80228245 -4.28893247 -2.9837788   0.          0.          0.        ]]\n",
      "\n",
      "Results on the test are :::::::::::::::: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.78      0.95      0.86        19\n",
      "         1.0       0.94      0.75      0.83        20\n",
      "\n",
      "    accuracy                           0.85        39\n",
      "   macro avg       0.86      0.85      0.85        39\n",
      "weighted avg       0.86      0.85      0.84        39\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature:\n",
      " [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.55487949  0.\n",
      "   0.          0.          1.4193945   0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.         -0.16890576\n",
      "   0.          0.          0.         -1.92054335  0.          0.\n",
      "   0.         -2.24571578  0.          0.          0.          0.        ]]\n",
      "\n",
      "Results on the test are :::::::::::::::: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.88      0.79      0.83        19\n",
      "         1.0       0.82      0.90      0.86        20\n",
      "\n",
      "    accuracy                           0.85        39\n",
      "   macro avg       0.85      0.84      0.85        39\n",
      "weighted avg       0.85      0.85      0.85        39\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------L1 Regularization -----------------------------#\n",
    "print(\"\\n_______________________________________Logistic Regression with L1 regularization ___________________________________________\\n\")\n",
    "C = [10, 1, .1]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    clf.fit(x_train, Ytrain)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:\\n', clf.coef_)\n",
    "    y_pred = clf.predict(Xtest);\n",
    "    print(\"\\nResults on the test are :::::::::::::::: \\n\")\n",
    "    print(classification_report(Ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
